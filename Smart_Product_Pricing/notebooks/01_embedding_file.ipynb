{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-13T06:33:08.439657Z",
     "iopub.status.busy": "2025-10-13T06:33:08.438999Z",
     "iopub.status.idle": "2025-10-13T06:34:32.354079Z",
     "shell.execute_reply": "2025-10-13T06:34:32.353416Z",
     "shell.execute_reply.started": "2025-10-13T06:33:08.439623Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "!pip install -q transformers torch Pillow tqdm aiohttp aiofiles\n",
    "\n",
    "import torch\n",
    "from transformers import AutoTokenizer, AutoModel\n",
    "from PIL import Image\n",
    "import aiohttp, asyncio, aiofiles\n",
    "import os, time\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm import tqdm "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-13T06:34:32.355716Z",
     "iopub.status.busy": "2025-10-13T06:34:32.355301Z",
     "iopub.status.idle": "2025-10-13T06:35:06.794076Z",
     "shell.execute_reply": "2025-10-13T06:35:06.793313Z",
     "shell.execute_reply.started": "2025-10-13T06:34:32.355698Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# =========================\n",
    "# 1Ô∏è‚É£ Load Model\n",
    "# =========================\n",
    "model_name = \"jinaai/jina-clip-v2\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name,trust_remote_code = True)\n",
    "model = AutoModel.from_pretrained(model_name,trust_remote_code = True)\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "model.to(device)\n",
    "model.eval()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-13T06:35:06.795558Z",
     "iopub.status.busy": "2025-10-13T06:35:06.794933Z",
     "iopub.status.idle": "2025-10-13T07:03:18.965174Z",
     "shell.execute_reply": "2025-10-13T07:03:18.964455Z",
     "shell.execute_reply.started": "2025-10-13T06:35:06.795539Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# =========================\n",
    "# 0Ô∏è‚É£ Imports & Setup\n",
    "# =========================\n",
    "import os, time, asyncio, aiohttp, aiofiles\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "from tqdm import tqdm\n",
    "import torch\n",
    "\n",
    "# Assume `model` and `device` are already defined\n",
    "# model: JinaCLIPModel or similar\n",
    "# device: \"cuda\" or \"cpu\"\n",
    "\n",
    "# =========================\n",
    "# 1Ô∏è‚É£ Load Dataset\n",
    "# =========================\n",
    "train_df = pd.read_csv(\"/kaggle/input/test-csv/test.csv\")  # columns: image_link, catalog_content\n",
    "sample_df = train_df.iloc[:75000].reset_index(drop=True)\n",
    "print(f\"Using {len(sample_df)} samples for embedding extraction.\")\n",
    "\n",
    "texts = sample_df[\"catalog_content\"].tolist()  # all rows are valid\n",
    "urls = sample_df[\"image_link\"].tolist()        # all rows are valid URLs\n",
    "\n",
    "# =========================\n",
    "# 2Ô∏è‚É£ Image Cache + Placeholder\n",
    "# =========================\n",
    "os.makedirs(\"cache_images\", exist_ok=True)\n",
    "\n",
    "# Create a single black placeholder image\n",
    "placeholder_path = \"cache_images/placeholder.jpg\"\n",
    "if not os.path.exists(placeholder_path):\n",
    "    Image.new(\"RGB\", (224, 224), color=(0, 0, 0)).save(placeholder_path)\n",
    "\n",
    "async def download_image(session, url, idx, retries=2):\n",
    "    \"\"\"Download image asynchronously with retries, return placeholder if fails.\"\"\"\n",
    "    cache_path = f\"cache_images/{idx}.jpg\"\n",
    "    if os.path.exists(cache_path):\n",
    "        return cache_path\n",
    "    for attempt in range(retries + 1):\n",
    "        try:\n",
    "            async with session.get(url, timeout=10) as response:\n",
    "                if response.status == 200:\n",
    "                    async with aiofiles.open(cache_path, 'wb') as f:\n",
    "                        await f.write(await response.read())\n",
    "                    return cache_path\n",
    "        except:\n",
    "            continue\n",
    "    # Return placeholder if all attempts fail\n",
    "    return placeholder_path\n",
    "\n",
    "async def batch_download(urls):\n",
    "    async with aiohttp.ClientSession() as session:\n",
    "        tasks = [download_image(session, url, i) for i, url in enumerate(urls)]\n",
    "        return await asyncio.gather(*tasks)\n",
    "\n",
    "# =========================\n",
    "# 3Ô∏è‚É£ Encoding Functions\n",
    "# =========================\n",
    "@torch.no_grad()\n",
    "def encode_texts(texts, batch_size=128):\n",
    "    \"\"\"Encodes text embeddings in FP32.\"\"\"\n",
    "    all_embs = []\n",
    "    for i in range(0, len(texts), batch_size):\n",
    "        batch = texts[i:i+batch_size]\n",
    "        emb = model.encode_text(batch, convert_to_tensor=True, device=device)\n",
    "        all_embs.append(emb.cpu())\n",
    "    return torch.cat(all_embs)  # shape: [num_rows, text_dim]\n",
    "\n",
    "@torch.no_grad()\n",
    "def encode_images(img_paths, batch_size=32):\n",
    "    \"\"\"Yields image embeddings and their corresponding indices.\"\"\"\n",
    "    imgs, batch_indices = [], []\n",
    "    for i, path in enumerate(img_paths):\n",
    "        try:\n",
    "            img = Image.open(path).convert(\"RGB\") if path is not None else None\n",
    "            if img is not None:\n",
    "                imgs.append(img)\n",
    "                batch_indices.append(i)\n",
    "        except:\n",
    "            # Rare corrupted image, use placeholder\n",
    "            img = Image.open(placeholder_path).convert(\"RGB\")\n",
    "            imgs.append(img)\n",
    "            batch_indices.append(i)\n",
    "        \n",
    "        # If batch full or last image\n",
    "        if len(imgs) == batch_size or i == len(img_paths) - 1:\n",
    "            if imgs:\n",
    "                with torch.autocast(device_type=device, dtype=torch.float16):\n",
    "                    batch_emb = model.encode_image(imgs)\n",
    "                yield batch_indices, batch_emb\n",
    "            imgs, batch_indices = [], []\n",
    "\n",
    "def fuse_embeddings(text_emb, image_emb, method=\"concat\"):\n",
    "    \"\"\"Fuse text and image embeddings with L2 normalization.\"\"\"\n",
    "    if method == \"concat\":\n",
    "        fused = torch.cat([text_emb, image_emb], dim=-1)\n",
    "    else:\n",
    "        fused = text_emb + image_emb\n",
    "    return fused / fused.norm(p=2, dim=-1, keepdim=True)\n",
    "\n",
    "# =========================\n",
    "# 4Ô∏è‚É£ Main Embedding Extraction\n",
    "# =========================\n",
    "async def main():\n",
    "    start_time = time.time()\n",
    "    \n",
    "    # -------------------------\n",
    "    # 1Ô∏è‚É£ Download images\n",
    "    # -------------------------\n",
    "    print(\"üì• Downloading images asynchronously...\")\n",
    "    img_paths = await batch_download(urls)\n",
    "    \n",
    "    # -------------------------\n",
    "    # 2Ô∏è‚É£ Encode text embeddings\n",
    "    # -------------------------\n",
    "    print(\"üß† Encoding text embeddings...\")\n",
    "    text_embs = encode_texts(texts, batch_size=128)  # FP32 tensor\n",
    "    \n",
    "    # -------------------------\n",
    "    # 3Ô∏è‚É£ Encode images & fuse embeddings\n",
    "    # -------------------------\n",
    "    print(\"üñº Encoding image embeddings and fusing...\")\n",
    "    \n",
    "    fused_embs = None\n",
    "    placeholder_img_emb = None\n",
    "    \n",
    "    for batch_indices, img_embs in tqdm(encode_images(img_paths, batch_size=32), desc=\"Processing images\"):\n",
    "        img_embs_tensor = torch.tensor(img_embs, dtype=torch.float32)\n",
    "        \n",
    "        # Initialize fused_embs and placeholder after first batch\n",
    "        if fused_embs is None:\n",
    "            image_dim = img_embs_tensor.shape[1]\n",
    "            fused_dim = text_embs.shape[1] + image_dim\n",
    "            fused_embs = torch.zeros((len(texts), fused_dim), dtype=torch.float32)\n",
    "            placeholder_img_emb = torch.zeros((1, image_dim), dtype=torch.float32)\n",
    "        \n",
    "        # Handle any missing images in batch\n",
    "        if img_embs_tensor.shape[0] < len(batch_indices):\n",
    "            full_embs = placeholder_img_emb.repeat(len(batch_indices), 1)\n",
    "            full_embs[:img_embs_tensor.shape[0]] = img_embs_tensor\n",
    "            img_embs_tensor = full_embs\n",
    "        \n",
    "        # Fuse with text embeddings\n",
    "        fused_batch = fuse_embeddings(text_embs[batch_indices], img_embs_tensor)\n",
    "        fused_embs[batch_indices] = fused_batch\n",
    "\n",
    "    # -------------------------\n",
    "    # 4Ô∏è‚É£ Done\n",
    "    # -------------------------\n",
    "    fused_embs_np = fused_embs.numpy()\n",
    "    total_time = time.time() - start_time\n",
    "    print(f\"\\n‚úÖ Done! {len(fused_embs_np)} embeddings created.\")\n",
    "    print(f\"‚è± Total time: {total_time:.2f}s (~{total_time/len(fused_embs_np):.3f}s per sample)\")\n",
    "    \n",
    "    # -------------------------\n",
    "    # 5Ô∏è‚É£ Save embeddings\n",
    "    # -------------------------\n",
    "    np.save(\"/kaggle/working/test_70k_75k.npy\", fused_embs_np)\n",
    "    print(\"üíæ Saved fused embeddings ‚Üí train_fused_embeddings20k_30k.npy\")\n",
    "\n",
    "# Run the async main\n",
    "await main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "gpu",
   "dataSources": [
    {
     "datasetId": 8472554,
     "sourceId": 13357642,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 8476020,
     "sourceId": 13362522,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 31154,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
